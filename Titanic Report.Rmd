---
title: 'Titanic: Machine Learning from Diaster'
author: "AC"
date: "July 19, 2016"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

  The sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.

One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.

In this project, I have completed the analysis of what sorts of people were likely to survive. In particular, I have applied the tools of machine learning to predict which passengers survived the tragedy.  

The dataset looks like the following:

------
```{r}
suppressWarnings(suppressMessages(library(DMwR)))
library(DMwR)
train <- read.csv("train.csv")
test <- read.csv("test.csv")
```
```{r}
#Training data set
head(train[,1:3],2)
head(train[,4:7],2)
head(train[,8:12],2)
```

------

```{r}
#Test data set - No "Survived" column
head(test[,1:3],2)
head(test[,4:7],2)
head(test[,8:11],2)

```
------

On closely observing the data, we see that there are a few missing values in the dataset.

------
```{r}
train[c(6,18,20),4:7]
```
------

To deal with the missing values, we use the _K-Nearest Neighbours (KNN)_ algorithm and replace the missing values with the approximated values. Before we apply the _KNN_ algorithm it is important to first merge the training and test datasets.

The merged dataset is obtained by binding of the rows of the two sets. Before binding, we need to make sure that the column titles are the same. In our case, test data set does not have the "Survived" column. So we create one and merge.

------
```{r}
test$Survived <- NA
merge_data <-  rbind(train,test)
#Number of rows in each data-set
nrow(train)       # 891
nrow(test)        # 418
nrow(merge_data)  #1309
#Applying KNN algorithm
knnOutput <- knnImputation(merge_data[, !names(merge_data) %in% "Survived"])
merge_data <- cbind.data.frame(knnOutput,Survived = merge_data$Survived) 
merge_data$Age <- as.integer(merge_data$Age)
merge_data[c(6,18,20),4:7]      #Filled NA values
```
------

##Feature Addition
Now since the data is in order, we will try to extract more features from the data. The names of the people have titles. So data can be aggregated based on titles. Similarly, the Surnames of the people can help identify family members. These features have been added in the following code snippet:

------
```{r}
#Extracting meaning from name of the person in the data
name <- as.character(merge_data$Name)

title <-sapply(name, FUN =  function(x) {(strsplit(x,split = '[,.]'))[[1]][2]})
title <- sub(' ','',title)

surname <- sapply(name, FUN =  function(x) {(strsplit(x,split = '[,.]'))[[1]][1]})

table(title)  #Original titles
title <- as.vector(title)

title[title %in% c('Capt','Don','Major', 'Sir')] <- 'Sir' 
title[title %in% c('Dona','Lady','the Countess', 'Jonkheer','Mlle','Mme')] <- 'Lady' 
title[title %in% 'Ms'] <- 'Miss'
title <- as.factor(title);

table(title)  #Grouped Titles

merge_data$Title <- title

#Including family size

merge_data$familySize <- NA
merge_data$familySize <- merge_data$SibSp + merge_data$Parch + 1

merge_data$family_set <- paste(as.character(merge_data$familySize), surname, sep = "")
merge_data$family_set[merge_data$familySize <3] <- 'small'
char <- merge_data$family_set


famIssue <- data.frame(table(merge_data$family_set))
famIssue <- famIssue[famIssue$Freq<3,]

char1 <- famIssue$Var1
char[char %in% char1] <- 'small'

merge_data$family_set <- char
head(merge_data$family_set)

```
-------

##Splitting the Dataset
We performed all the feature addition operations on the data and now its time to separate the two data sets into two separate files. It can be done with the following simple command:

-------
```{r}
merge_data$family_set<- as.factor(merge_data$family_set)
train <-  merge_data[1:nrow(train),]
test <- merge_data[(nrow(train) + 1):nrow(merge_data),]
nrow(train)
nrow(test)

```
--------

##Training a Conditional Forest
Random forests or random decision forests are an ensemble learning method for classification, regression and other tasks, that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees.

Conditional forest is an implementation of the random forest and bagging ensemble algorithms utilizing conditional inference trees as base learners.

We train our forest based on the Sex, Age, Pclass, SibSp, Parch, Fare and Title of the train set data. This can be done in R using the following code:

-----------
```{r}

#Conditional Random Forest
suppressWarnings(suppressMessages(library(party)))
library(party)
set.seed(755)

fit <- cforest(as.factor(Survived) ~ Sex + Age + Pclass + SibSp + Parch + Fare +
                      Title + Embarked + familySize + family_set,
                    data = train, controls = cforest_unbiased(ntree = 2000, mtry=3))

```
----------

##Predicting Survivals from Test Data
The number of survivals in the test data can be predicted using the _predict_ function in R.

---------
```{r}
pre <- predict(fit, test, OOB=TRUE, type = "response")
```
---------

##Creating an Excel Result File
Once we get the predicted values of survivals, we can create an excel file of the result in whatever format we want. For sake of convenience, we will be creating an csv file with two columns _Passenger ID_ and _Survival Output_. It can be prepared using the following lines of code:

---------
```{r}
predictions <- data.frame(PassengerId = test$PassengerId, Survived = pre)
write.csv(predictions, file = "myoutput.csv", row.names = FALSE)

```
---------

##References
1. Dataset and instructions: Kaggle 
   <https://www.kaggle.com/c/titanic>
   
2. General methodolgy: <http://trevorstephens.com/kaggle-titanic-tutorial/getting-started-with-r/>

